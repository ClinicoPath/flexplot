sample(1:10, size=pm*p)
data[,cols] = NA
head(data)
cols
cols = sample(1:10, size=pm*p)
data[,cols] = NA
head(data)
cors(data)
cor(data, use="complete.obs")
data
cor(data, use="complete.obs")
data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)
cols = sample(1:10, size=pm*p)
data[1:10,cols] = NA
cor(data, use="complete.obs")
cor.mat = cor(data)
cols = sample(1:10, size=pm*p)
cor.mat[cols, cols] = NA
cor.mat
#### 2. Simulate k studies#
studies = array(dim=c(p,p,k))#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[,,i] = cor.mat#
}
studies
studies = data.frame(study=1:k, estimate=paste0("V", 1:unique.cors))
studies = data.frame(matrix(NA, nrow=k, ncol=paste0("V", 1:unique.cors) + 1))
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))
studies
names(studies) = c("study", paste0("cor", 1:p))
studies
names(studies) = c("study", paste0("cor", 1:unique.cors))
studies
require(Matrix)
vechs(cor.mat)
require(OpenMx)
vechs(cor.mat)
cor.mat
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,] = vechs(cor.mat)#
}
require(OpenMx)#
#
		#### set parameters#
a = b= c = .4#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 50#
priors = c(0, .5)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}
studies
studies_prior = matrix(nrow=weight*2*k, ncol=ncol(studies))
require(OpenMx)#
#
		#### set parameters#
a = b= c = .4#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 50#
priors = c(0, .5)	### limits of priors#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create the prior matrix#
studies_prior = matrix(nrow=weight*2*k, ncol=ncol(studies))
studies_prior
studies_prior = matrix(runif(rows*ncol(studies), priors[1], priors[5]), nrow=weight*2*k, ncol=ncol(studies))
rows = weight*2*k
studies_prior = matrix(runif(rows*ncol(studies), priors[1], priors[5]), nrow=weight*2*k, ncol=ncol(studies))
rows
rows*ncol(studies)
priors
runif(rows*ncol(studies), priors[1], priors[5])
rows*ncol(studies)
runif(n=rows*ncol(studies), min=priors[1], max=priors[5])
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])
random.cors
studies_prior = matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies))
studies_prior
posterior_cors = cbind(studies, studies_prior)
posterior_cors
require(mice)
?mice
imputated.dataset = mice(data, m=imps, method="rf")
pool(imputed.dataset)
pool(imputated.dataset)
fit = with(data=imputated.dataset, colMeans())
fit = with(data=imputated.dataset, colMeans(imputated.dataset))
fit = with(data=imputated.dataset, colMeans(.))
?with
fit = with(data=imputated.dataset, colMeans(x))
studies_prior
names(imputated.dataset)
id = mice(data, m=imps, method="rf")
id$imp
names(id)
?mice
id$imp$V1
id = mice(posterior_cors, m=imps, method="rf")
posterior_cors
names(posterior_cors) = names(studies)
posterior_cors = data.frame(cbind(studies, studies_prior))
names(posterior_cors) = names(studies)
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")
names(studies)
posterior_cors = data.frame(cbind(studies, studies_prior))
names(posterior_cors)
dim(studies)
unique.cors
dim(posterior_cors)
posterior_cors = data.frame(rbind(studies, studies_prior))
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))
names(studies_prior) = names(studies)
posterior_cors = data.frame(rbind(studies, studies_prior))
posterior_cors
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")
id$imp$V1
names(id)
id$data
names(id)
id$imp
with(id, colMeans)
with(id, colMeans())
mean.cors = 1:unique.cors
id$imp
?complete
i=1
newd = complete(id, i)
newd
colMeans(newd)
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)
newd = complete(id, i)
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)#
for (i in 1:length(mean.cores)){#
	newd = complete(id, i)#
	mean.cores[,i] = colMeans(newd)#
}
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)#
for (i in 1:length(mean.cores)){#
	newd = complete(id, i)#
	mean.cors[,i] = colMeans(newd)#
}
for (i in 1:length(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[,i] = colMeans(newd)#
}
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)#
for (i in 1:length(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[,i] = colMeans(newd[-1])#
}
mean.cors
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)#
for (i in 1:length(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,1] = colMeans(newd[-1])#
	mean.cors[i,2] = i#
}
mean.cors = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=imps))
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))
mean.cors
i = 1
newd = complete(id, i)
newd
colMeans(newd[-1])
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:length(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[-1])#
}
mean.cors
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[-1])#
}
mean.cors
colMeans(mean.cors)
rho
colMeans(mean.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 50#
priors = c(0, .5)	### limits of priors#
weight = .25			### confidence of bayesian estimate (.5 means you give equal weight to the prior)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[-1])#
}#
colMeans(mean.cors)[c(1,2,10)]
apply(mean.cors,2,sd)[c(1,2,10)]
newd
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}
sd.cors
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
colMeans(mean.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.3, .7)	### limits of priors (vary the bias?)#
weight = .25			### confidence of bayesian estimate (.5 means you give equal weight to the prior)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.3, .7)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)
#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))
data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk
if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}
cols = sample(1:p, size=pm*p)
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .1#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
colMeans(mean.cors)[c(1,2,p)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .1#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,p)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .1#
k = 30#
N = 200#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,p)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .1#
k = 10#
N = 200#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,p)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
install.packages("BRugs")
if(!require(R2OpenBUGS)) install.packages("R2OpenBUGS")
install.packages("R2OpenBUGS")
require(R2OpenBugs)
require(R2OpenBUGS)
data(schools)
install.packages("BRugs")
install.packages("rjags")
clear()#
#
require(flexplot)#
require(cowplot)#
require(tidyverse)#
#
		#### data preparation#
d = read.csv("research/9 steps/data/nsduh_ninsteps.csv")#
		#### just note who does drugs vs. not, then subset#
m= d %>% mutate(drugs = ifelse(her.rec=="past 30 days" | her.rec == ">30 < 12 mo", "yes", "no")) %>% #
	filter(drugs=="yes") %>%#
	mutate(health.rating = factor(health.rating, levels=rev(1:5), labels=c("poor", "fair", "good", "very good", "excellent"), ordered=T))#
	### report statistical significance#
mod = (lm(distress~health.rating + MI, data=m))#
anova(mod)#
rel = m %>% select(k6_1:k6_6) %>% filter_all(all_vars(. < 6))#
require(psych)#
require(lavaan)#
		#### type of estimate for reliability depends on number of factors. See how many there are#
f1 = fa(rel, nfactors=1)	#
f2 = fa(rel, nfactors=2, rotate="promax")#
f2	#### find the factors with EFA#
#
		### do cfa#
model1 = '#
	g =~ k6_1 + k6_2 + k6_3 + k6_4 + k6_5 + k6_6 #
'#
model2 = '#
	g1 =~ k6_2 + k6_4 + k6_5 + k6_6 #
	g2 =~ k6_1 + k6_3 	#
	g1~~g2#
'#
#
fit1 = cfa(model1, data=rel)#
fit2 = cfa(model2, data=rel)#
options(scipen=10)#
cbind(m1=inspect(fit1, 'fit.measures'), m2=inspect(fit2, 'fit.measures'))#
	### nearly all measures agree on a two factor solution		#
	#### look at various says to estimate reliability#
cronbach = alpha(rel); #
omeg2 = omega(rel, nfactors=2); #
cronbach$total$raw_alpha#
omeg2$omega.tot#
	#### fairly similar and high#
		### univariate plots#
flexplot(distress~1, data=m)#
flexplot(health.rating~1, data=m)#
flexplot(MI~1, data=m)#
#
		#### bivariate plots#
bivar1 = flexplot(distress~MI | health.rating, data=m)		#
#
		#### let's combine these datasets since they're sparse at the end#
m2 = m; levels(m2$health.rating) = c("fair", "fair", "good", "very good", "very good")#
	#### results from aggregating#
	flexplot(health.rating~1, data=m2)#
			#### now re-visualize#
	bivar2 = flexplot(distress~MI | health.rating, data=m2)				#
	plot_grid(bivar1, bivar2)#
			#### now visualize residuals of lm (even though it's a bad idea to do LM)#
	visualize(mod, "residuals")		#
			#### compare various models#
	require(splines)#
	mod_polyt = MASS::polr(distress~MI * health.rating, data=m2 %>% mutate(distress = factor(distress)))#
	mod_gam = glm(distress~MI * health.rating + I(MI^2), data=m2 %>% mutate(distress = distress+1), family=Gamma(link="log"))#
	mod_rf = randomForest::randomForest(distress~MI * health.rating, data=m2 %>% mutate(distress = distress+1))#
	mod_spline = glm(distress~bs(MI, knots=.125, degree=2)*health.rating, data=m2 %>% mutate(distress = distress+1), family=Gamma(link="log"))#
			#### show the models#
	compare.fits(distress~MI | health.rating, data=m2, mod_polyt, mod_gam, jitter=c(0, .4), alpha=.2)		### two bad models#
	compare.fits(distress~MI | health.rating, data=m2, mod_rf, mod_spline, jitter=c(0, .4), alpha=.2, ghost.line="black")		### two good models#
	reduced_coplot= compare.fits(distress~MI | health.rating, data=m2, mod_rf, jitter=c(0, .4), alpha=.2, ghost.line="black")+ theme(legend.position="none") + facet_grid(~health.rating) 	### just look at RF model#
		####  now residualize the effect of MI#
	m2 = m2 %>% mutate(rf_residuals =  distress - predict(mod_rf) + mean(distress))#
	reduced_avp	= flexplot(rf_residuals~health.rating, data=m2) + labs(x="Health Rating", y="Distress | MI")#
#
### give parameter estimates#
means1 = predict(mod_rf, m2 %>% mutate(MI = quantile(MI, .1))%>% filter(health.rating=="fair" | health.rating=="very good")) %>% unique()#
#
m2$health.rating#
#### results from not aggregating#
#### results from aggregating#
			#### compare various models#
	require(splines)#
	mod_polyt = MASS::polr(distress~MI * health.rating, data=m %>% mutate(distress = factor(distress)))#
	mod_gam = glm(distress~MI * health.rating + I(MI^2), data=m %>% mutate(distress = distress+1), family=Gamma(link="log"))#
	mod_rf = randomForest::randomForest(distress~MI * health.rating, data=m %>% mutate(distress = distress+1))#
	mod_spline = glm(distress~bs(MI, knots=.125, degree=2)*health.rating, data=m %>% mutate(distress = distress+1), family=Gamma(link="log"))#
			#### show the models#
	compare.fits(distress~MI | health.rating, data=m, mod_polyt, mod_gam, jitter=c(0, .4), alpha=.2)		### two bad models#
	compare.fits(distress~MI | health.rating, data=m, mod_rf, mod_spline, jitter=c(0, .4), alpha=.2, ghost.line="black")		### two good models#
	full_coplot = compare.fits(distress~MI | health.rating, data=m, mod_rf, jitter=c(0, .4), alpha=.2, ghost.line="black")+ theme(legend.position="none")+ facet_grid(~health.rating)		### just look at RF model#
		####  now residualize the effect of MI#
	m = m %>% mutate(rf_residuals =  distress - predict(mod_rf) + mean(distress))#
	full_avp = flexplot(rf_residuals~health.rating, data=m) + labs(x="Health Rating", y="Distress | MI")
plot_grid(reduced_coplot, reduced_avp, nrow=1)
full_coplot = compare.fits(distress~MI | health.rating, data=m, mod_rf, jitter=c(0, .4), alpha=.2, ghost.line="black", ghost.reference=list(health.rating="good"))+ theme(legend.position="none")+ facet_grid(~health.rating)		### just look at RF model
full_coplot
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines() %>% length()) %>%#
  sum()
require(dplyr)#
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines() %>% length()) %>%#
  sum()
require(tidyverse)#
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines() %>% length()) %>%#
  sum()
require(tidyverse)#
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines() %>% length())
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines() %>% length()) %>% length
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][jpg]$") %>%#
  sapply(function(x) x %>% readLines() %>% length()) %>% length
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][pdf]$") %>%#
  sapply(function(x) x %>% readLines() %>% length()) %>% length
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][png]$") %>%#
  sapply(function(x) x %>% readLines() %>% length()) %>% length
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][png]$")
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][pdf]$")
list.files(path = "research/Collaborations", pattern="pdf$", full.names = TRUE, recursive = TRUE) %>% length
list.files(path = "research/Collaborations", pattern="jpg$", full.names = TRUE, recursive = TRUE) %>% length
list.files(path = "research/Collaborations", pattern="png$", full.names = TRUE, recursive = TRUE) %>% length
list.files(path = "research/Collaborations", pattern="png$", full.names = TRUE, recursive = TRUE)
list.files(path = "research/Collaborations", pattern="pdf$", full.names = TRUE, recursive = TRUE)
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines()
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines()
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines()
}}
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines())
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>%#
  sapply(function(x) x %>% readLines()) %>%#
  sum()
require(tidyverse)#
list.files(path = "research/Collaborations", recursive = T, full.names = T) %>%#
  str_subset("[.][R]$") %>% length()
data(exercise_data)
d = exercise_data
require(flexplot)
data(exercise_data)
d = exercise_data
b = flexplot(weight.loss~motivation, data=d)
a = flexplot(weight.loss~therapy.type, data=d)#
b = flexplot(weight.loss~motivation, data=d)#
cowplot::plot_grid(a,b)
b = flexplot(weight.loss~motivation, data=d, method="lm")
cowplot::plot_grid(a,b)
jmvtools::install("research/RPackages/flexplot")
getwd()
jmvtools::install("research/RPackages/flexplot")
jmvtools::install("research/RPackages/flexplot")
getwd()
setwd("research/RPackages/flexplot")
jmvtools::install("research/RPackages/flexplot")
jmvtools::install("")
jmvtools::install()
data(blood_pressure)
head(blood_pressure)
jmvtools::install()
clear()
load("/Users/fife/Dropbox/jamovi.Rda")
ls()
fifer::clear()
load("/Users/fife/Dropbox/jamovi.Rda")
ls()
head(k)
head(p)
p
ls()
head(ghost.given)
head(d_smooth)
data(birthweight)
head(birthweight)
jmvtools::install()
jmvtools::install()
fifer::clear()
load("/Users/fife/Dropbox/jamovi.Rda")
ls()
p
head(k)
warnings()
fifer::clear()
load("/Users/fife/Dropbox/jamovi.Rda")
ls()
head(k)
p
jmvtools::install()
jmvtools::install()
jmvtools::install()
data(nsduh)
head(nsduh)
devtools::check()
devtools::check()
data(tablesaw_injury)
head(tablesaw_injury)
load("/Users/fife/Dropbox/research/RPackages/flexplot/data/tablesaw_injury.rda")
fifer::clear()
load("/Users/fife/Dropbox/research/RPackages/flexplot/data/tablesaw_injury.rda")
ls()
devtools::check()
jmvtools::install()
jmvtools::install()
jmvtools::install()
jmvtools::install()
