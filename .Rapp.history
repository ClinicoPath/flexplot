id$data
names(id)
id$imp
with(id, colMeans)
with(id, colMeans())
mean.cors = 1:unique.cors
id$imp
?complete
i=1
newd = complete(id, i)
newd
colMeans(newd)
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)
newd = complete(id, i)
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)#
for (i in 1:length(mean.cores)){#
	newd = complete(id, i)#
	mean.cores[,i] = colMeans(newd)#
}
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)#
for (i in 1:length(mean.cores)){#
	newd = complete(id, i)#
	mean.cors[,i] = colMeans(newd)#
}
for (i in 1:length(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[,i] = colMeans(newd)#
}
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)#
for (i in 1:length(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[,i] = colMeans(newd[-1])#
}
mean.cors
mean.cors = data.frame(estimate = names(studies[-1]), impnum = imps)#
for (i in 1:length(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,1] = colMeans(newd[-1])#
	mean.cors[i,2] = i#
}
mean.cors = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=imps))
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))
mean.cors
i = 1
newd = complete(id, i)
newd
colMeans(newd[-1])
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:length(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[-1])#
}
mean.cors
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[-1])#
}
mean.cors
colMeans(mean.cors)
rho
colMeans(mean.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 50#
priors = c(0, .5)	### limits of priors#
weight = .25			### confidence of bayesian estimate (.5 means you give equal weight to the prior)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[-1])#
}#
colMeans(mean.cors)[c(1,2,10)]
apply(mean.cors,2,sd)[c(1,2,10)]
newd
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}
sd.cors
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
colMeans(mean.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.3, .7)	### limits of priors (vary the bias?)#
weight = .25			### confidence of bayesian estimate (.5 means you give equal weight to the prior)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.3, .7)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 10	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)
#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))
data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk
if (runif(1)<pk){#
		cols = sample(1:10, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}
cols = sample(1:p, size=pm*p)
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .05			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .3#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .1#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,10)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
colMeans(mean.cors)[c(1,2,p)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .1#
k = 30#
N = 1000#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,p)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .1#
k = 30#
N = 200#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,p)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
require(OpenMx)#
#
		#### set parameters#
a = b= c = .5#
p = 5	#### number of variables#
dij = .1#
k = 10#
N = 200#
pm = .5#
pk = .9#
imps = 10#
priors = c(.1, .5)	### limits of priors (vary the bias?)#
weight = .5			### confidence of bayesian estimate (.5 means you give equal weight to the prior, less means more weight to the data)#
#
	#### 1. create variance/covariance matrix#
unique.cors = p*(p-1)/2	#
devechs = rep(dij, times=unique.cors-3)#
rho = matrix(dij, nrow=p, ncol=p)#
diag(rho) = 1#
rho[1:3, 1:3][lower.tri(rho[1:3, 1:3])] = c(a,b,c)#
rho[1:3, 1:3][upper.tri(rho[1:3, 1:3])] = c(a,b,c)#
	#### 2. Simulate k studies#
studies = data.frame(matrix(NA, nrow=k, ncol=unique.cors + 1))#
names(studies) = c("study", paste0("cor", 1:unique.cors))#
#
for (i in 1:k){#
	data = MASS::mvrnorm(N, mu=rep(0, times=p), Sigma = rho)#
	cor.mat = cor(data)#
	#### delete data if random number < pk#
	if (runif(1)<pk){#
		cols = sample(1:p, size=pm*p)#
		cor.mat[cols, cols] = NA#
	}#
	### put in matrix#
	studies[i,1] = i#
	studies[i,-1] = vechs(cor.mat)#
}#
#
	#### create and populate the prior matrix#
rows = weight*2*k	#
random.cors = runif(n=rows*ncol(studies), min=priors[1], max=priors[2])#
studies_prior = data.frame(matrix(random.cors, nrow=weight*2*k, ncol=ncol(studies)))#
names(studies_prior) = names(studies)#
#
	#### combine the matrices#
posterior_cors = data.frame(rbind(studies, studies_prior))#
	#### impute the RF#
require(mice)#
id = mice(posterior_cors, m=imps, method="rf")#
	#### loop through and average the correlations#
mean.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
sd.cors = data.frame(matrix(nrow=imps, ncol=unique.cors))#
i = 1#
for (i in 1:nrow(mean.cors)){#
	newd = complete(id, i)#
	mean.cors[i,] = colMeans(newd[,-1])#
	sd.cors[i,] = apply(newd[,-1], 2, sd)#
}#
colMeans(mean.cors)[c(1,2,p)]#
apply(mean.cors,2,sd)[c(1,2,10)] + colMeans(sd.cors)[c(1,2,10)]
install.packages("BRugs")
if(!require(R2OpenBUGS)) install.packages("R2OpenBUGS")
install.packages("R2OpenBUGS")
require(R2OpenBugs)
require(R2OpenBUGS)
data(schools)
install.packages("BRugs")
install.packages("rjags")
clear()#
#
require(flexplot)#
require(cowplot)#
require(tidyverse)#
#
		#### data preparation#
d = read.csv("research/9 steps/data/nsduh_ninsteps.csv")#
		#### just note who does drugs vs. not, then subset#
m= d %>% mutate(drugs = ifelse(her.rec=="past 30 days" | her.rec == ">30 < 12 mo", "yes", "no")) %>% #
	filter(drugs=="yes") %>%#
	mutate(health.rating = factor(health.rating, levels=rev(1:5), labels=c("poor", "fair", "good", "very good", "excellent"), ordered=T))#
	### report statistical significance#
mod = (lm(distress~health.rating + MI, data=m))#
anova(mod)#
rel = m %>% select(k6_1:k6_6) %>% filter_all(all_vars(. < 6))#
require(psych)#
require(lavaan)#
		#### type of estimate for reliability depends on number of factors. See how many there are#
f1 = fa(rel, nfactors=1)	#
f2 = fa(rel, nfactors=2, rotate="promax")#
f2	#### find the factors with EFA#
#
		### do cfa#
model1 = '#
	g =~ k6_1 + k6_2 + k6_3 + k6_4 + k6_5 + k6_6 #
'#
model2 = '#
	g1 =~ k6_2 + k6_4 + k6_5 + k6_6 #
	g2 =~ k6_1 + k6_3 	#
	g1~~g2#
'#
#
fit1 = cfa(model1, data=rel)#
fit2 = cfa(model2, data=rel)#
options(scipen=10)#
cbind(m1=inspect(fit1, 'fit.measures'), m2=inspect(fit2, 'fit.measures'))#
	### nearly all measures agree on a two factor solution		#
	#### look at various says to estimate reliability#
cronbach = alpha(rel); #
omeg2 = omega(rel, nfactors=2); #
cronbach$total$raw_alpha#
omeg2$omega.tot#
	#### fairly similar and high#
		### univariate plots#
flexplot(distress~1, data=m)#
flexplot(health.rating~1, data=m)#
flexplot(MI~1, data=m)#
#
		#### bivariate plots#
bivar1 = flexplot(distress~MI | health.rating, data=m)		#
#
		#### let's combine these datasets since they're sparse at the end#
m2 = m; levels(m2$health.rating) = c("fair", "fair", "good", "very good", "very good")#
	#### results from aggregating#
	flexplot(health.rating~1, data=m2)#
			#### now re-visualize#
	bivar2 = flexplot(distress~MI | health.rating, data=m2)				#
	plot_grid(bivar1, bivar2)#
			#### now visualize residuals of lm (even though it's a bad idea to do LM)#
	visualize(mod, "residuals")		#
			#### compare various models#
	require(splines)#
	mod_polyt = MASS::polr(distress~MI * health.rating, data=m2 %>% mutate(distress = factor(distress)))#
	mod_gam = glm(distress~MI * health.rating + I(MI^2), data=m2 %>% mutate(distress = distress+1), family=Gamma(link="log"))#
	mod_rf = randomForest::randomForest(distress~MI * health.rating, data=m2 %>% mutate(distress = distress+1))#
	mod_spline = glm(distress~bs(MI, knots=.125, degree=2)*health.rating, data=m2 %>% mutate(distress = distress+1), family=Gamma(link="log"))#
			#### show the models#
	compare.fits(distress~MI | health.rating, data=m2, mod_polyt, mod_gam, jitter=c(0, .4), alpha=.2)		### two bad models#
	compare.fits(distress~MI | health.rating, data=m2, mod_rf, mod_spline, jitter=c(0, .4), alpha=.2, ghost.line="black")		### two good models#
	reduced_coplot= compare.fits(distress~MI | health.rating, data=m2, mod_rf, jitter=c(0, .4), alpha=.2, ghost.line="black")+ theme(legend.position="none") + facet_grid(~health.rating) 	### just look at RF model#
		####  now residualize the effect of MI#
	m2 = m2 %>% mutate(rf_residuals =  distress - predict(mod_rf) + mean(distress))#
	reduced_avp	= flexplot(rf_residuals~health.rating, data=m2) + labs(x="Health Rating", y="Distress | MI")#
#
### give parameter estimates#
means1 = predict(mod_rf, m2 %>% mutate(MI = quantile(MI, .1))%>% filter(health.rating=="fair" | health.rating=="very good")) %>% unique()#
#
m2$health.rating#
#### results from not aggregating#
#### results from aggregating#
			#### compare various models#
	require(splines)#
	mod_polyt = MASS::polr(distress~MI * health.rating, data=m %>% mutate(distress = factor(distress)))#
	mod_gam = glm(distress~MI * health.rating + I(MI^2), data=m %>% mutate(distress = distress+1), family=Gamma(link="log"))#
	mod_rf = randomForest::randomForest(distress~MI * health.rating, data=m %>% mutate(distress = distress+1))#
	mod_spline = glm(distress~bs(MI, knots=.125, degree=2)*health.rating, data=m %>% mutate(distress = distress+1), family=Gamma(link="log"))#
			#### show the models#
	compare.fits(distress~MI | health.rating, data=m, mod_polyt, mod_gam, jitter=c(0, .4), alpha=.2)		### two bad models#
	compare.fits(distress~MI | health.rating, data=m, mod_rf, mod_spline, jitter=c(0, .4), alpha=.2, ghost.line="black")		### two good models#
	full_coplot = compare.fits(distress~MI | health.rating, data=m, mod_rf, jitter=c(0, .4), alpha=.2, ghost.line="black")+ theme(legend.position="none")+ facet_grid(~health.rating)		### just look at RF model#
		####  now residualize the effect of MI#
	m = m %>% mutate(rf_residuals =  distress - predict(mod_rf) + mean(distress))#
	full_avp = flexplot(rf_residuals~health.rating, data=m) + labs(x="Health Rating", y="Distress | MI")
plot_grid(reduced_coplot, reduced_avp, nrow=1)
full_coplot = compare.fits(distress~MI | health.rating, data=m, mod_rf, jitter=c(0, .4), alpha=.2, ghost.line="black", ghost.reference=list(health.rating="good"))+ theme(legend.position="none")+ facet_grid(~health.rating)		### just look at RF model
full_coplot
library("readxl")
getwd()
files = list.files("research/Collaborations/literacy")
files
files = list.files("research/Collaborations/literacy", full.names=T)
read_excel(files[3], sheet=1)
?read_excel
sheets = excel_sheets(files[3])
sheets
data = read_excel(files[3], sheet=sheets[1])
data = read_excel(files[3], sheet=sheets[1]) %>% data.frame()
require(dplyr)
data = read_excel(files[3], sheet=sheets[1]) %>% data.frame()
data
flexplot(Scripture.on.own.or.with.help.~1, data=data)
require(flexplot)
flexplot(Scripture.on.own.or.with.help.~1, data=data)
flexplot(Age~1, data=data)
files[3]
nrow(data)
d = read.csv("research/Collaborations/literacy/progress.csv")
head(d)
d = read.csv("research/Collaborations/literacy/progress.csv") #
d = d[-1:2,]#
head(d)
d[,6]
d[,19]
d[,38]
d[,37]
names(d)[6] = "start"
d = read.csv("research/Collaborations/literacy/progress.csv") #
d = d[-1:2,]#
names(d)[6] = "start"#
names(d)[19] = "before.class"#
names(d)[37] = "after.class"
head(d)
d$start
d$before.class
d$before.class = as.numeric(d$before.class)
d$before.class
d = read.csv("research/Collaborations/literacy/progress.csv")
d = d[-1:2,]
d$before.class = as.numeric(as.character(d$before.class))
d = read.csv("research/Collaborations/literacy/progress.csv")
names(d)[6] = "start"#
names(d)[19] = "before.class"#
names(d)[37] = "after.class"#
d$before.class = as.numeric(as.character(d$before.class))
d$before.class
d = read.csv("research/Collaborations/literacy/progress.csv")
d = d[-1:2,]
names(d)[6] = "start"
names(d)[19] = "before.class"
names(d)[37] = "after.class"
d$before.class
d$before.class = factor(d$before.class, levels=c("1", ""), labels=c("yes", "no"))
d$before.class
d$after.class = factor(d$after.class, levels=c("1", ""), labels=c("yes", "no"))
d[,c("before.class", "after.class")]
d = read.csv("research/Collaborations/literacy/progress.csv") #
d = d[-1:2,]#
names(d)[6] = "start"#
names(d)[19] = "before.class"#
names(d)[37] = "after.class"#
d$before.class[d$before.class==""] = 0
d = read.csv("research/Collaborations/literacy/progress.csv", stringAsFactors=F)
d = read.csv("research/Collaborations/literacy/progress.csv", StringAsFactors=F)
?read.csv
d = read.csv("research/Collaborations/literacy/progress.csv", stringsAsFactors =F)
d = d[-1:2,]#
names(d)[6] = "start"#
names(d)[19] = "before.class"#
names(d)[37] = "after.class"#
d$before.class[d$before.class==""] = 0
d$before.class
d$before.class = as.numeric(d$before.class)
d$before.class
d$after.class[d$after.class ==""] = 0#
d$after.class = as.numeric(d$after.class)
d$change = d$after.class - d$before.class
d$change
d = read.csv("research/Collaborations/literacy/progress.csv", stringsAsFactors =F) #
d = d[-1:2,]#
d[3,c(6,19,37)]
d = read.csv("research/Collaborations/literacy/progress.csv", stringsAsFactors =F) #
head(d)
d[,17]
d = read.csv("research/Collaborations/literacy/progress.csv", stringsAsFactors =F) #
d[,17]
d[,35]
d[3,c(6,35,35+18)]
35+18
d[3,c(6,35,53)]
c(6,35,53)
fifer::excel.cols("BA")
contents("fifer")
require(fifer)
contents("fifer")
fifer::excelCols("BA")
?fifer::excelCols("BA")
fifer::excelMatch("BA")
fifer::excelMatch
fifer::excelMatch("BA")
fifer::excelMatch("BA", names(d))
names(d)
d[3,c(6,35,41)]
d[3,c(6,35,53)]
d[1:10,c(6,35,53)]
d = read.csv("research/Collaborations/literacy/progress.csv", stringsAsFactors =F)
d = read.csv("research/Collaborations/literacy/progress.csv", stringsAsFactors =F) #
d = d[-1:2,]#
contents("fifer")#
d[1:10,c(6,35,53)]#
names(d)[6] = "start"#
names(d)[35] = "before.class"#
names(d)[53] = "after.class"#
d$before.class[d$before.class==""] = 0#
d$before.class = as.numeric(d$before.class)#
d$after.class[d$after.class ==""] = 0#
d$after.class = as.numeric(d$after.class)#
d$change = d$after.class - d$before.class
d$change
flexplot(change~1, data=d)
require(tidyverse)
flexplot(change~1, data=d)
remove.packages("fifer")
flexplot(change~1, data=d)
flexplot::flexplot(change~1, data=d)
d$change = factor(d$after.class - d$before.class, levels=c(-1,0,1), labels=c("Worse", "Same", "Improved"))
flexplot::flexplot(change~1, data=d)
flexplot::flexplot(change~1, data=d) + labs(x="Read Scriptures By Themselves")
flexplot::flexplot(start~1, data=d)
flexplot::flexplot(start~change, data=d)
flexplot::flexplot(start~change, data=d, jitter=c(.2, .3))
flexplot::flexplot(start~change, data=d, jitter=c(.2, .4))
devtools::install("research/RPackages/flexplot")
flexplot::flexplot(start~change, data=d, jitter=c(.2, .4))  + labs(x="Difference Pre to Post In Read Scriptures Solo")
flexplot::flexplot(start~change, data=d, jitter=c(.2, .4))  + labs(x="Difference Pre to Post In Read Scriptures Solo", y="Years in Program")
d = read.csv("research/Collaborations/literacy/progress.csv", stringsAsFactors =F) #
d = d[-1:2,]#
names(d)[6] = "start"#
names(d)[35] = "before.class"#
names(d)[53] = "after.class"#
d$before.class[d$before.class==""] = 0#
d$before.class = as.numeric(d$before.class)#
d$after.class[d$after.class ==""] = 0#
d$after.class = as.numeric(d$after.class)#
d$change = factor(d$after.class - d$before.class, levels=c(-1,0,1), labels=c("Worse", "Same", "Improved"))#
require(tidyverse)#
flexplot::flexplot(change~1, data=d) + labs(x="Read Scriptures By Themselves")
flexplot::flexplot(change~1, data=d) + labs(x="Read Scriptures By Themselves")
flexplot::flexplot(start~change, data=d, jitter=c(.2, .4))  + labs(x="Difference Pre to Post In Read Scriptures Solo", y="Years in Program")
flexplot::flexplot(change~1, data=d) + labs(x="Read Scriptures By Themselves")
require(fifer2)
make.data(means=c(10, 15), sds=10, names=c("Treatment", "Outcome"), groups=c("Treatment", "Control"))
make.data(means=c(10, 15), sds=10, names=c("Treatment", "Outcome"), groups=c("Treatment", "Control"), n=30)
make.data(means=c(10, 15), sds=c(10,10), names=c("Treatment", "Outcome"), groups=c("Treatment", "Control"), n=c(15, 15))
make.data(means=c(10, 15), sds=c(10,10), names=c("Outcome", "Treatment"), groups=c("Treatment", "Control"), n=c(15, 15))
data = make.data(means=c(10, 15), sds=c(10,10), names=c("Outcome", "Treatment"), groups=c("Treatment", "Control"), n=c(15, 15))
t.test(Outcome~Treatment, data=data)
t.test(Outcome~Treatment, data=data)$p.value
data = make.data(means=c(10, 15), sds=c(10,10), names=c("Outcome", "Treatment"), groups=c("Treatment", "Control"), n=c(15, 15))#
t.test(Outcome~Treatment, data=data)$p.value
require(fifer2)#
#
p.vals = 1:10#
for (i in 1:length(p.vals)){#
data = make.data(means=c(10, 15), sds=c(10,10), names=c("Outcome", "Treatment"), groups=c("Treatment", "Control"), n=c(15, 15))#
p.vals[i] = t.test(Outcome~Treatment, data=data)$p.value#
}
p.vals
p.vals = data.frame(p.vals)
flexplot(p.vals~1, data=p.vals)
flexplot::flexplot(p.vals~1, data=p.vals)
p.vals = 1:1000#
for (i in 1:length(p.vals)){#
data = make.data(means=c(10, 15), sds=c(10,10), names=c("Outcome", "Treatment"), groups=c("Treatment", "Control"), n=c(15, 15))#
p.vals[i] = t.test(Outcome~Treatment, data=data)$p.value#
}#
p.vals = data.frame(p.vals)#
#
flexplot::flexplot(p.vals~1, data=p.vals)
length(which(p.vals<0.05))
length(which(p.vals<0.05))/length(p.vals)
length(p.vals)
length(which(p.vals<0.05))/nrow(p.vals)
flexplot::flexplot(p.vals~1, data=p.vals) + labs(x="Computed P-Value From 1,000 Replications")
flexplot::flexplot(p.vals~1, data=p.vals) + lab(x="Computed P-Value From 1,000 Replications")
require(tidyverse)
flexplot::flexplot(p.vals~1, data=p.vals) + labs(x="Computed P-Value From 1,000 Replications")
flexplot::flexplot(p.vals~1, data=p.vals) + labs(x="Computed P-Value From 1,000 Replications", y="Number of Studies")
?geom_text
flexplot::flexplot(p.vals~1, data=p.vals) + labs(x="Computed P-Value From 1,000 Replications", y="Number of Studies") +#
  annotate("text", label = "plot mpg vs. wt", x = .75, y = 100, size = 8, colour = "red")
length(which(p.vals<0.05))/nrow(p.vals)
annotate("text", label = "# of Significance p-values: 252", x = .75, y = 100, size = 8, colour = "red")
require(tidyverse)#
flexplot::flexplot(p.vals~1, data=p.vals) + labs(x="Computed P-Value From 1,000 Replications", y="Number of Studies") +#
  annotate("text", label = "# of Significance p-values: 252", x = .75, y = 100, size = 8, colour = "red")
annotate("text", label = "# of Significance p-values:\n 252", x = .75, y = 100, size = 8, colour = "red")
flexplot::flexplot(p.vals~1, data=p.vals) + labs(x="Computed P-Value From 1,000 Replications", y="Number of Studies") +#
  annotate("text", label = "# of Significance p-values:\n 252", x = .75, y = 100, size = 8, colour = "red")
require(tidyverse)#
flexplot::flexplot(p.vals~1, data=p.vals) + labs(x="Computed P-Value From 1,000 Replications", y="Number of Studies") +#
  annotate("text", label = "# of Significance p-values:\n 252", x = .55, y = 100, size = 8, colour = "red")
devtools::check("research/RPackages/flexplot")
data(birthweight)
head(birthweight)
data(nsduh)
head(nsduh)
devtools::check("research/RPackages/flexplot")
devtools::document("research/RPackages/flexplot")
devtools::check("research/RPackages/flexplot")
devtools::check("research/RPackages/flexplot")
setwd("research/RPackages/flexplot")
devtools::build()
devtools::check()
devtools::check()
data(nsduh)
names(nsduh)
names(nsduh)[14]
names(nsduh)[15]
names(nsduh)[15] = "whodas.impairment"
save(ndsuh, "data/nsduh.Rdat")
save(ndsuh, list="data/nsduh.Rdat")
save(ndsuh, file="data/nsduh.Rdat")
save(nsduh, file="data/nsduh.Rdat")
devtools::check()
save(nsduh, file="data/nsduh.rda")
devtools::check()
save(nsduh, file="data/nsduh.rda")
devtools::check()
a=c("gender","health","income","motivation","muscle.gain","muscle.gain.missing","rewards","satisfaction","six.mo.weight","therapy.type","weight.loss")
a
b=c("gender","health","income","motivation","muscle.gain","muscle.gain.missing", "rewards","satisfaction","six.mo.weight","therapy.type","weight","loss")
a %in% b
a = c("MI","age","alc.freq","alc.rec","attend.rel.serv","cig.freq","cig.rec", "coc.rec","cocain.freq","county","dep.pas.yr","distress","education", "health.rating","her.rec","heroin.freq","income","inpatient","major.dep","military","moves.past5","outpatient","race","rel.inf.dec","sex", "whodas.impairment")#
#
b = c("MI","age","alc.freq","alc.rec","attend.rel.serv","cig.freq","cig.rec",#
"coc.rec","cocain.freq","country","dep.pas.yr","distress","education",#
"health.rating","her.rec","heroin.freq","income","inpatient","major.dep",#
"military","moves.past5","outpatient","race","rel.inf.dec","sex",#
"whodas.impairment")
a %in% b
a[!(a %in% b)]
devtools::check()
devtools::check()
devtools::use_build_ignore("build")
?devtools::use_build_ignore("build")
devtools::check()
?build
