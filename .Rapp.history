ls()
head(data)
formula
self$options
self$options$se
self$options$suppr
self$options$bins
flexplot(formula, data, se=self$options$se, spread=se.type, ghost.line="gray", bins=self$options$bins, suppress_smooth = self$options$suppr)
flexplot::flexplot(formula, data, se=self$options$se, spread=se.type, ghost.line="gray", bins=self$options$bins, suppress_smooth = self$options$suppr)
flexplot::flexplot(formula, data, se=self$options$se, ghost.line="gray", bins=self$options$bins, suppress_smooth = self$options$suppr)
formula
devtools::install_github("dustinfife/flexplot")
data(blood_pressure)
require(flexplot)
data(blood_pressure)
head(blood_pressure)
data(diet)
head(diet)
data(exercise_data)
require(flexplot)
data(exercise_data
)
require(flexplot)#
data(exercise_data)#
mod1 = lm(weight.loss~motivation + therapy.type, data=exercise_data)#
mod2 = rlm(weight.loss~motivation + therapy.type, data=exercise_data)#
model.comparison(mod1, mod2)
mod2 = MASS::rlm(weight.loss~motivation + therapy.type, data=exercise_data)
model.comparison(mod1, mod2)
data(exercise_data)
require(flexplot)
data(exercise_data)
mod1 = lm(weight.loss~therapy.type + motivation, data=exercise_data)
mod2 = lm(weight.loss~therapy.type * motivation, data=exercise_data)
formula =weight.loss~therapy.type | motivation; data=exercise_data; model1= mod1; model2= mod2
return.preds=F
silent=F
report.se=F
re=F
pred.type="response"
#### if mod2 is null..#
	if (is.null(model2)){#
		model2 = model1#
		old.mod = 1#
	} else {#
		old.mod = 0#
	}#
#
	#### get type of model#
	model1.type = class(model1)[1]#
	model2.type = class(model2)[1]	#
	#### extract the terms from each MODEL#
	testme1 = formula(model1); terms.mod1=all.vars(testme1)[-1]#
	testme2 = formula(model2); terms.mod2=all.vars(testme2)[-1]#
	testme = unique(all.vars(testme1)[-1], all.vars(testme2)[-1])#
	##### extract variable names#
	variables = all.vars(formula)#
    outcome = variables[1]#
    predictors = variables[-1]#
    #### for the rare occasion where deleting missing data changes the levels...#
    if (length(predict(model1))<nrow(data) | length(predict(model2))<nrow(data)){#
      data = na.omit(data[,variables])#
    }    #
    ##### make sure they're putting the same variables from formula in terms#
	if (!(all(predictors %in% testme))){#
		stop(paste0("Sorry, but some variables in formula don't match what's in the model. Specifically: ", paste0(variables[!(variables%in%terms.mod1)], collapse=",")))#
	}#
	##### make sure they're using the right dataset#
	if (!(all(predictors %in% names(data)))){#
		stop(paste0("Sorry, but some variables in formula don't match what's in the dataset. Specifically: ", paste0(variables[!(variables%in%data)], collapse=","), ". Did you input the wrong dataset?"))#
	}	#
	#### create random column just to make the applies work (yeah, it's hacky, but it works)#
    data$reject = 1:nrow(data); data$reject2 = 1:nrow(data)#
    predictors = c(predictors, "reject", "reject2")#
#
    #### get variable types#
    numb = names(which(unlist(lapply(data[,predictors], is.numeric))))#
    cat = names(which(!(unlist(lapply(data[,predictors], is.numeric)))))#
#
    ##### make "quadriture" points for quant variables#
    var.mins = apply(data[, numb], 2, min, na.rm=T)#
    var.max = apply(data[, numb], 2, max, na.rm=T)    #
    min.max = data.frame(var.mins, var.max); min.max$size = c(50, rep(10, nrow(min.max)-1))#
	f = function(d){seq(from=d[1], to=d[2], length.out=d[3])}#
	min.max = as.list(apply(min.max, 1, f))#
#
    #### get unique values for categorical vars#
    if (length(cat)==1){#
    	un.vars = lapply(data[cat], unique)    	#
    } else {#
		un.vars =lapply(data[,cat], unique); names(un.vars) = cat#
	}#
    #### combine into one dataset#
    all.vars = c(min.max, un.vars)    #
    #### get rid of extra variables#
    tot.vars = length(predictors)#
    rejects = grep("reject", names(all.vars))#
	all.vars = all.vars[-rejects]#
	all.vars = lapply(all.vars, function(x) x[!is.na(x)])#
	pred.values = expand.grid(all.vars)#
	##### look for interactions and remove them#
	if (length(grep(":", terms.mod1))>0){#
		terms.mod1 = terms.mod1[-grep(":", terms.mod1)]#
		model1.type = ifelse(model1.type=="lm", "interaction", model1.type)#
	}#
	if (length(grep(":", terms.mod2))>0){#
		terms.mod2 = terms.mod2[-grep(":", terms.mod1)]#
		model2.type = ifelse(model2.type=="lm", "interaction", model2.type)#
	}	#
	##### look for polynomials and remove them#
	if (length(grep("^2", terms.mod1, fixed=T, value=T))>0 ){#
		terms.mod1 = terms.mod1[-grep("^2", terms.mod1, fixed=T)]#
		model1.type = ifelse(model1.type=="lm", "polynomial", model1.type)#
	}#
	if (length(grep("^2", terms.mod2, fixed=T, value=T))>0 & model1.type=="lm"){#
		terms.mod2 = terms.mod2[-grep("^2", terms.mod1, fixed=T)]#
		model2.type = ifelse(model2.type=="lm", "polynomial", model2.type)#
	}	#
	#### if the outcome is an ordered factor...#
	#### if it's not in model 1:#
	#### input the mean (if numeric) or a value (if categorical)#
	if (length(which(!(terms.mod1 %in% predictors)))>0){#
		not.in.there = terms.mod1[which(!(terms.mod1 %in% predictors))]#
		for (i in 1:length(not.in.there)){#
			if (is.numeric(data[,not.in.there[i]])){#
				if (!silent){message(paste0("Note: You didn't choose to plot ", not.in.there[i], " so I am inputting the median\n"))}#
				pred.values[,not.in.there[i]] = median(data[,not.in.there[i]], na.rm=T)#
			} else {#
				val = unique(data[,not.in.there[i]])[1]#
				if (!silent){message(paste0("Note: You didn't choose to plot ", not.in.there[i], " so I am inputting '", val, "'\n"))}#
				pred.values[,not.in.there[i]] = val#
			}#
		}#
	}#
	#### generate predictions#
	if (model1.type == "lmerMod" | model1.type == "glmerMod"){#
		pred.mod1 = data.frame(prediction = predict(model1, pred.values, type="response", re.form=NA), model= "fixed effects")		#
	} else if (model1.type == "polr"){#
		pred.mod1 = data.frame(prediction = predict(model1, pred.values, type="class", re.form=NA), model= model1.type)		#
	} else if (model1.type == "lm" | model1.type == "polynomial" | model1.type=="interaction"){#
		int = ifelse(report.se, "confidence", "none")#
		pred.mod1 = data.frame(prediction = predict(model1, pred.values, interval=int), model=model1.type)#
	} else {	#
		int = ifelse(report.se, "confidence", "none")#
		pred.mod1 = data.frame(prediction = predict(model1, pred.values, type=pred.type, interval=int), model= model1.type)		#
	}#
#
	#### generate separate predictions for random effects#
	if ((model2.type == "lmerMod" | model2.type == "glmerMod") & re){#
		pred.mod2 = data.frame(prediction = predict(model2, pred.values, type="response"), model= "random effects")	#
		old.mod=0	#
	} else if ((model2.type == "lmerMod" | model2.type == "glmerMod") & !re){#
		pred.mod2 = pred.mod1#
	} else if (model2.type == "polr"){#
		pred.mod2 = data.frame(prediction = predict(model2, pred.values, type="class", re.form=NA), model= model2.type)		#
	} else if (model2.type == "lm" | model2.type == "polynomial" | model2.type=="interaction"){#
		int = ifelse(report.se, "confidence", "none")#
		pred.mod2 = data.frame(prediction = predict(model2, pred.values, interval="confidence")[,1], model=model2.type)#
	} else {#
		pred.mod2 = data.frame(prediction = predict(model2, pred.values, type= pred.type), model= model2.type)		#
	}#
	#### convert polyr back to numeric (if applicable)#
	if (model1.type == "polr" | model2.type == "polr"){#
		data[,outcome] = as.numeric(as.character(data[,outcome]))		#
		pred.mod1$prediction = as.numeric(as.character(pred.mod1$prediction))#
		pred.mod2$prediction = as.numeric(as.character(pred.mod2$prediction))		#
	}
deparse(substitute(model1))
pred.mod1$model = paste0(deparse(substitute(model1)), " (", model1.type, ")", collapse="")#
		pred.mod2$model = paste0(deparse(substitute(model2)), " (", model2.type, ")", collapse="")#
	#}#
	#### report one or two coefficients, depending on if they supplied it#
	if (old.mod==0){#
		prediction.model = rbind(pred.mod1, pred.mod2)#
		prediction.model = cbind(pred.values, prediction.model)#
	} else {#
		prediction.model = pred.mod1#
		prediction.model = cbind(pred.values, prediction.model)#
	}#
	#### eliminate those predictions that are higher than the range of the data#
	if (!is.factor(data[,outcome])){#
	min.dat = min(data[,outcome], na.rm=T); max.dat = max(data[,outcome], na.rm=T)#
		if (length(which(prediction.model$prediction>max.dat)>0 | length(which(prediction.model$prediction<min.dat)))){#
			prediction.model  = prediction.model[-which(prediction.model$prediction>max.dat | prediction.model$prediction<min.dat), ]#
		}#
	} else {#
		#### if they supply a factor, convert it to a number!!!!!#
		prediction.model$prediction = round(as.numeric(as.character(prediction.model$prediction)), digits=3)#
	}
flexplot(formula, data=data, prediction=prediction.model, suppress_smooth=T, se=
)
setwd("research/RPackages/flexplot")
devtools::load_all()
devtools::test()
d = exercise_data#
d$wl = d$weight.loss + .8*d$motivation*as.numeric(d$rewards)
model.me = lm(weight.loss ~ motivation+therapy.type, data = exercise_data)
model.int = lm(weight.loss ~ motivation*therapy.type, data = exercise_data)
compare.fits(weight.loss ~ motivation | therapy.type, #
               data = exercise_data, model.me, model.int, ghost.line = "black"))
compare.fits(weight.loss ~ motivation | therapy.type, #
               data = exercise_data, model.me, model.int, ghost.line = "black")
mod = lm(wl ~motivation+rewards, data=d)
mod2 = lm(wl ~motivation*rewards, data=d)
compare.fits(wl~motivation|rewards, data=d, model1=mod, model2=mod2)
mod = lm(weight.loss~motivation, data=d)
compare.fits(weight.loss~motivation, data=d, model1=mod)
mod1 = lm(weight.loss~therapy.type * motivation * health * muscle.gain * I(motivation^2), data=d)
mod1 = lm(weight.loss~therapy.type * motivation * health * muscle.gain * I(motivation^2), data=d)
mod2 = lm(weight.loss~therapy.type + motivation + health + muscle.gain + I(motivation^2), data=d)
compare.fits(weight.loss ~muscle.gain | motivation + health, data=d, model1=mod1, model2=mod2)
compare.fits(weight.loss ~muscle.gain +therapy.type | motivation + health, data=d, model1=mod1)
data("relationship_satisfaction")
full.mod = lm(satisfaction~communication * separated , data=relationship_satisfaction)
reduced.mod = lm(satisfaction~communication + separated , data=relationship_satisfaction)
compare.fits(satisfaction~communication|separated, data=relationship_satisfaction, full.mod, reduced.mod)
mod = lm(weight.loss~rewards, data=d)#
  require(MASS)#
  mod2 = rlm(weight.loss~rewards, data=d)
compare.fits(formula=weight.loss~rewards, data=d, model1=mod, model2=mod2)
require(randomForest)#
  model1 = randomForest::randomForest(wl~motivation + gender + rewards, data=d)#
  model2 = lm(wl~motivation * gender * rewards, data=d)		### use the same predictors in both models
compare.fits(wl~motivation | gender + rewards, data=d, model1, model2)
mod1 = glm(weight.loss~motivation + health + gender, data=d, family="Gamma")
mod2 = lm(weight.loss~motivation + health + gender, data=d)
compare.fits(weight.loss~motivation | health + gender, data=d, mod1, mod2)
d$weight.loss = d$weight.loss + 1 + abs(min(d$weight.loss, na.rm=T))
mod1 = glm(weight.loss~motivation + health + gender, data=d, family="Gamma")
mod2 = lm(weight.loss~motivation + health + gender, data=d)
compare.fits(weight.loss~motivation | health + gender, data=d, mod1, mod2)
require(fifer)#
  data(authors); d= authors[1:1000,]#
  mod1 = lm(Daily.Units.Sold~Sale.Price*Publisher, data=d)#
  mod2 = glm(Daily.Units.Sold~Sale.Price*Publisher, data=d, family=quasipoisson(link="log"))
compare.fits(Daily.Units.Sold~Sale.Price|Publisher, data=d, mod1, mod2)
cat1 = lm(weight.loss~therapy.type, data=d)
data(exercise_data)
d = exercise_data
cat1 = lm(weight.loss~therapy.type, data=d)
estimates(cat1)
names(estimates(cat1))
estimates(cat1)$difference.matrix$cohens.1
estimates(cat1)$difference.matrix
estimates(cat1)$difference.matrix$cohens.d
mod = lm(weight.loss~therapy.type + gender, data=d)
estimates(mod)$difference.matrix$cohens.d[1]
estimates(mod)$difference.matrix$cohens.d
estimates(mod)
mod = lm(weight.loss~therapy.type * gender, data=d)
estimates(mod)
estimates(mod)$semi.p
cat1 = lm(weight.loss~motivation, data=d)	#
  estimates(cat1)
estimates(cat1)$numbers
estimates(cat1)$numbers.summary
estimates(cat1)$numbers.summary$estimate[2]
mod = lm(weight.loss~motivation + income, data=d)	#
  estimates(mod)
estimates(mod)$numbers.summary$std.upper[3]
mod = lm(weight.loss~motivation + therapy.type + gender, data=d)	#
  estimates(mod)
estimates(mod)$difference.matrix
mod = lm(weight.loss~motivation + income + gender, data=d)
estimates(mod)
names( estimates(mod))
estimates(mod)$semi.p
mod = lm(weight.loss~motivation + I(motivation^2), data=d)	#
  estimates(mod)
require(testthat)
cat1 = lm(weight.loss~therapy.type, data=d)
expect_equal(estimates(cat1)$difference.matrix$cohens.d[1], .63)
expect_equal(estimates(cat1)$difference.matrix$cohens.d[1], .631)
estimates(cat1)$difference.matrix$cohens.d[1]
expect_equal(estimates(cat1)$difference.matrix$cohens.d[1], .6305667)
estimates(cat1)$difference.matrix$cohens.d[1]
?expect_equal
expect_equal(estimates(cat1)$difference.matrix$cohens.d[1], .6305667, tolerance = 0.002)
cat1 = lm(weight.loss~therapy.type, data=d)
expect_equal(estimates(cat1)$difference.matrix$cohens.d[1], .6305667, tolerance = 0.002)#
  ##### two categoricals#
  mod = lm(weight.loss~therapy.type + gender, data=d)	#
  expect_equal(estimates(mod)$difference.matrix$cohens.d[4], -.1, tolerance = 0.002)#
  ##### interaction#
  mod = lm(weight.loss~therapy.type * gender, data=d)	#
  expect_equal(estimates(mod)$semi.p, .009, tolerance = 0.002)
estimates(mod)$difference.matrix$cohens.d[4]
estimates(mod)
mod = lm(weight.loss~therapy.type + gender, data=d)
estimates(mod)$difference.matrix
expect_equal(estimates(mod)$difference.matrix$cohens.d[4], -.1024, tolerance = 0.002)
mod = lm(weight.loss~therapy.type * gender, data=d)
estimates(mod)$semi.p
expect_equal(estimates(mod)$semi.p, .009, tolerance = 0.002)
expect_equal(estimates(mod)$semi.p, .009, tolerance = 0.002, tolerance = 0.002)
expect_equal(estimates(mod)$semi.p, .00934, tolerance = 0.002)
estimates(mod)
expect_true(estimates(mod)$semi.p<0.01 & estimates(mod)$semi.p>0.009)
expect_equal(estimates(cat1)$numbers.summary$estimate[2], .1856, tolerance = 0.002)
cat1 = lm(weight.loss~motivation, data=d)
expect_equal(estimates(cat1)$numbers.summary$estimate[2], .1856, tolerance = 0.002)
mod = lm(weight.loss~motivation + income, data=d)
expect_equal(estimates(mod)$numbers.summary$std.upper[3], -.1898, tolerance = 0.002)
mod = lm(weight.loss~motivation + therapy.type + gender, data=d)
expect_equal(estimates(mod)$difference.matrix$difference[4] = -.93229, tolerance = 0.002)
expect_equal(estimates(mod)$difference.matrix$difference[4], -.93229, tolerance = 0.002)
mod = lm(weight.loss~motivation + income + gender, data=d)
expect_equal(estimates(mod)$semi.p[3] = .007958, tolerance = 0.002)
mod = lm(weight.loss~motivation + income + gender, data=d)
expect_equal(estimates(mod)$semi.p[3] = .007958, tolerance = 0.002)
expect_equal(estimates(mod)$semi.p[3], .007958, tolerance = 0.002)
estimates(mod)$semi.p[3]
expect_equal(estimates(mod)$semi.p[3], .007958, tolerance = 0.002)
estimates(mod)$semi.p[3]
expect_equal(estimates(mod)$semi.p[3], .007958, tolerance = 0.002)
traceback()
estimates(mod)
estimates(mod)$semi.p
estimates(mod)$semi.p[3]
expect_true(estimates(mod)$semi.p[3]<0.01 & estimates(mod)$semi.p[3]>0.007)
mod = lm(weight.loss~motivation + I(motivation^2), data=d)
expect_equal(estimates(mod)$numbers.summary$std.upper[3], -.53, tolerance = 0.002)
data(tablesaw)
head(tablesaw)
data(tablesaw)
head(tablesaw)
ls()
fifer::clear()
data(tablesaw)
ls()
data(tablesaw_injury)
tablesaw_injury
data(tablesaw.injury)
tablesaw.injury
d = tablesaw.injury
head(d)
data(criminal_data)
d = criminal_data
head(d)
d$rape
apply(d, 2, table)
head(d)
mod = glm(rape~ses + empathy + depression, data=d, family="binomial")
estimates(mod)
mod = glm(convictions~ses + empathy + depression, data=d, family=poisson)
estimates(mod)
mod
object = mod
terms = attr(terms(object), "term.labels")#
	#### get dataset#
	d = object$model#
	#### identify factors#
	if (length(terms)>1){#
		factors = names(which(unlist(lapply(d[,terms], is.factor))));#
		numbers = names(which(unlist(lapply(d[,terms], is.numeric))));#
	} else {#
		factors = terms[which(is.factor(d[,terms]))]#
		numbers = terms[which(is.numeric(d[,terms]))]#
	}
#### output predictions#
	n.func = function(term){anchor.predictions(object, term, shutup=T)$prediction}#
	preds = lapply(terms, n.func); names(preds) = terms
if (family(object)$link=="logit"){#
		coef.matrix = data.frame(raw.coefficients = coef(object), OR = exp(coef(object)), inverse.OR = 1/exp(coef(object)), standardized.OR = exp(standardized.beta(object, sd.y=F)), inverse.standardized.OR = 1/exp(standardized.beta(object, sd.y=F)))
} else if (family(object)$link=="log"){#
		coef.matrix = data.frame(raw.coefficients = coef(object), #
				multiplicative.coef = exp(coef(object)), #
				std.mult.coef = exp(standardized.beta(object, sd.y=F)))#
	} else if (family(object)$link=="inverse"){#
		coef.matrix = data.frame(raw.coefficients = coef(object), #
				inverse.coef = 1/((object)), #
				std.mult.coef = 1/(standardized.beta(object, sd.y=F)))#
	}
inverse.coef
family(object)$link
multiplicative.coef
family(object)$link=="log"
coef.matrix = data.frame(raw.coefficients = coef(object),
multiplicative.coef = exp(coef(object)),
std.mult.coef = exp(standardized.beta(object, sd.y=F)))
coef.matrix
coef.matrix[numbers,"Prediction Difference (+/- 1 SD)"] = sapply(preds[numbers], function(x){abs(round(x[2]-x[1], digits=2))})
coef.matrix[,1:5] = round(coef.matrix[,1:5], digits=3)
coef.matrix
coef.matrix[numbers,"Prediction Difference (+/- 1 SD)"] = sapply(preds[numbers], function(x){abs(round(x[2]-x[1], digits=2))})
coef.matrix
data.frame(lapply(coef.matrix, function(y) if(is.numeric(y)) round(y, 2) else y))
nms = row.names(coef.matrix)
coef.matrix[numbers,"Prediction Difference (+/- 1 SD)"] = sapply(preds[numbers], function(x){abs(round(x[2]-x[1], digits=2))})
nms = row.names(coef.matrix)
coef.matrix
coef.matrix = data.frame(lapply(coef.matrix, function(y) if(is.numeric(y)) round(y, 2) else y)); names(coef.matrix) = nms
coef.matrix
#### for those that are factors, put the first prediction in the -1 SD column#
	string.round = function(x, digits){#
		return.val = ifelse(round(x, digits)==0, paste0("<0.", rep(0, times=digits-1), "1"), round(x, digits=digits))#
		return.val#
	}#
	if (length(factors)>0){#
	for (i in 1:length(factors)){#
		current.pre = preds[factors[i]]#
		levs = levels(d[,factors[i]]); levs = paste0(factors[i], levs)#
		coef.matrix[levs[-1],"Prediction Difference (+/- 1 SD)"] = paste0(string.round(unlist(current.pre)[-1] - unlist(current.pre)[1], digits=2), " (relative to ", levs[1], ")")#
		if (length(factors)==1){#
			coef.matrix[1,"Prediction Difference (+/- 1 SD)"] = paste0(string.round(unlist(current.pre)[1], digits=2), " (", levs[1], " prediction)")#
			row.names(coef.matrix)[1] = levs[1]#
		}#
	}}#
	coef.matrix
devtools::load_all()
mod = glm(rape~ses + empathy + depression, data=d, family="binomial")#
estimates(mod)
data(criminal_data)
mod = glm(rape~ses + empathy + depression, data=d, family="binomial")
d = criminal_data
mod = glm(rape~ses + empathy + depression, data=d, family="binomial")
estimates(mod)
devtools::load_all()
data(criminal_data)#
d = criminal_data#
mod = glm(rape~ses + empathy + depression, data=d, family="binomial")#
estimates(mod)
devtools::load_all()
data(criminal_data)#
d = criminal_data#
mod = glm(rape~ses + empathy + depression, data=d, family="binomial")#
estimates(mod)
mod = glm(convictions~ses + empathy + depression, data=d, family=poisson)#
object = mod
estimates(mod)
head(d)
mod = glm(aggression~ses + empathy + depression, data=d, family=gamma)
?family
mod = glm(aggression~ses + empathy + depression, data=d, family=Gamma)
estimates(mod)
object = mod
terms = attr(terms(object), "term.labels")#
	#### get dataset#
	d = object$model#
	#### identify factors#
	if (length(terms)>1){#
		factors = names(which(unlist(lapply(d[,terms], is.factor))));#
		numbers = names(which(unlist(lapply(d[,terms], is.numeric))));#
	} else {#
		factors = terms[which(is.factor(d[,terms]))]#
		numbers = terms[which(is.numeric(d[,terms]))]#
	}#
#
	#### output predictions#
	n.func = function(term){anchor.predictions(object, term, shutup=T)$prediction}#
	preds = lapply(terms, n.func); names(preds) = terms#
	#### output coefficients#
	options(warn=-1)#
	if (family(object)$link=="logit"){#
		coef.matrix = data.frame(raw.coefficients = coef(object), OR = exp(coef(object)), inverse.OR = 1/exp(coef(object)), standardized.OR = exp(standardized.beta(object, sd.y=F)), inverse.standardized.OR = 1/exp(standardized.beta(object, sd.y=F)))#
	} else if (family(object)$link=="log"){#
		coef.matrix = data.frame(raw.coefficients = coef(object), #
				multiplicative.coef = exp(coef(object)), #
				std.mult.coef = exp(standardized.beta(object, sd.y=F)))#
	}
family(object)$link=="inverse"
coef(object)
1/((object))
inverse.coef = 1/(coef(object)),
inverse.coef = 1/(coef(object))
std.mult.coef = 1/(standardized.beta(object, sd.y=F))
if (family(object)$link=="logit"){#
		coef.matrix = data.frame(raw.coefficients = coef(object), OR = exp(coef(object)), inverse.OR = 1/exp(coef(object)), standardized.OR = exp(standardized.beta(object, sd.y=F)), inverse.standardized.OR = 1/exp(standardized.beta(object, sd.y=F)))#
	} else if (family(object)$link=="log"){#
		coef.matrix = data.frame(raw.coefficients = coef(object), #
				multiplicative.coef = exp(coef(object)), #
				std.mult.coef = exp(standardized.beta(object, sd.y=F)))#
	} else if (family(object)$link=="inverse"){#
		coef.matrix = data.frame(raw.coefficients = coef(object), #
				inverse.coef = 1/(coef(object)), #
				std.mult.coef = 1/(standardized.beta(object, sd.y=F)))#
	}
coef.matrix[numbers,"Prediction Difference (+/- 1 SD)"] = sapply(preds[numbers], function(x){abs(round(x[2]-x[1], digits=2))})#
	nms = row.names(coef.matrix); nms2 = names(coef.matrix)#
  	coef.matrix = data.frame(lapply(coef.matrix, function(y) if(is.numeric(y)) round(y, 3) else y), row.names=nms); names(coef.matrix) = nms2
coef.matrix
#### for those that are factors, put the first prediction in the -1 SD column#
	string.round = function(x, digits){#
		return.val = ifelse(round(x, digits)==0, paste0("<0.", rep(0, times=digits-1), "1"), round(x, digits=digits))#
		return.val#
	}#
	if (length(factors)>0){#
	for (i in 1:length(factors)){#
		current.pre = preds[factors[i]]#
		levs = levels(d[,factors[i]]); levs = paste0(factors[i], levs)#
		coef.matrix[levs[-1],"Prediction Difference (+/- 1 SD)"] = paste0(string.round(unlist(current.pre)[-1] - unlist(current.pre)[1], digits=2), " (relative to ", levs[1], ")")#
		if (length(factors)==1){#
			coef.matrix[1,"Prediction Difference (+/- 1 SD)"] = paste0(string.round(unlist(current.pre)[1], digits=2), " (", levs[1], " prediction)")#
			row.names(coef.matrix)[1] = levs[1]#
		}#
	}}#
	coef.matrix
mod = glm(aggression~ses + empathy + depression, data=d, family=Gamma)
estimates(mod)
devtools::load_all()
estimates(mod)
mod = glm(convictions~ses + empathy + depression, data=d, family=poisson)#
estimates(mod)$raw.coefficients[1]
mod = glm(convictions~ses + empathy + depression, data=d, family=poisson)
d = criminal_data#
head(d)
mod = glm(rape~ses + empathy + depression, data=d, family="binomial")
estimates(mod)
expect_equal(estimates(mod)$raw.coefficients[1], -98.915)
mod = glm(convictions~ses + empathy + depression, data=d, family=poisson)
mod
?family
estimates(mod)$raw.coefficients[1]
expect_equal(estimates(mod)$raw.coefficients[1], -.798)
mod = glm(aggression~ses + empathy + depression, data=d, family=Gamma)
expect_equal(estimates(mod)$raw.coefficients[1], .164)
